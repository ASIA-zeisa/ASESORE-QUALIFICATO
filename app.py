import os
import base64
import requests
import traceback
from flask import Flask, request, render_template_string
from pinecone import Pinecone
from openai import OpenAI
from dotenv import load_dotenv

# â”€â”€â”€ 0) Load env vars â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_ENV     = os.getenv("PINECONE_ENV")
PINECONE_INDEX   = os.getenv("PINECONE_INDEX")
OPENAI_API_KEY   = os.getenv("OPENAI_API_KEY")

# â”€â”€â”€ 0.5) Activation config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EXAM_CONFIG     = {i: 'off' for i in range(1, 61)}
EXAM_CONFIG.update({1: 'on', 2: 'on', 3: 'off', 4: 'off', 5: 'off'})
SECTION_OPTIONS = ['Lectura', 'RedacciÃ³n', 'MatemÃ¡ticas', 'Variable']
PREGUNTA_CONFIG = {i: 'off' for i in range(1, 61)}

# â”€â”€â”€ 0.7) Dummy vector for filter-only queries â€” must match index dimensions
DUMMY_VECTOR = [0.0] * 1536  # your Pinecone index has 1536 dimensions

# â”€â”€â”€ 1) Init Pinecone & OpenAI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
pc     = Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_ENV)
index  = pc.Index(PINECONE_INDEX)
client = OpenAI(api_key=OPENAI_API_KEY)
app    = Flask(__name__)

# â”€â”€â”€ 2) HTML + MathJax setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# (your existing HTML template here, unchanged)
HTML = '''â€¦'''  # truncated for brevity

@app.route('/', methods=['GET'])
def home():
    return render_template_string(
        HTML,
        exam_config     = EXAM_CONFIG,
        section_options = SECTION_OPTIONS
    )

# â”€â”€â”€ 4) Handle question â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.route('/preguntar', methods=['POST'])
def preguntar():
    try:
        texto        = (request.form.get('texto') or "").strip()
        examen       = request.form.get('examen')
        seccion      = request.form.get('seccion')
        pregunta_num = request.form.get('pregunta')
        image_file   = request.files.get('image')

        # block mixed inputs
        if texto and (examen or seccion or pregunta_num or image_file):
            return (
                "Si escribes tu pregunta, no puedes usar â€œExamenâ€, â€œSecciÃ³nâ€, "
                "â€œPreguntaâ€ ni subir imagen al mismo tiempo."
            ), 400

        # require at least one input
        if not (texto or examen or seccion or pregunta_num or image_file):
            return (
                "Proporciona texto, selecciona examen/secciÃ³n/pregunta o sube una imagen."
            ), 400

        # if exam-based lookup, require section & question
        if examen and not (seccion and pregunta_num):
            return "Cuando seleccionas examen, debes elegir secciÃ³n y pregunta.", 400

        # 4a) Exact-match lookup by metadata
        snippet = None
        if examen and seccion and pregunta_num:
            pine = index.query(
                vector=DUMMY_VECTOR,
                top_k=1,
                include_metadata=True,
                filter={
                    "exam":     int(examen),
                    "section":  seccion,
                    "question": int(pregunta_num)
                }
            )
            if pine.matches:
                meta    = pine.matches[0].metadata
                snippet = meta.get("text") or meta.get("answer")

        # 4b) If exact-match found, wrap & generate concise explanation
        if snippet:
            clean = snippet.strip('$')
            # build your system & user prompts hereâ€¦
            # call OpenAIâ€¦
            # set formatted_list accordingly
            formatted_list = f"<ol><li>\\({clean}\\)</li></ol>â€¦"
        else:
            # 4c) Fallback: embedding â†’ similarity â†’ LLM formatter (unchanged)
            # â€¦
            formatted_list = "â€¦"  # your existing fallback code

        # 4f) Return response
        response_fragment = (
            f"<p><strong>Enunciado:</strong> {texto}</p>"
            f"<p><strong>Examen:</strong> {examen}</p>"
            f"<p><strong>SecciÃ³n:</strong> {seccion}</p>"
            f"<p><strong>Pregunta nÂº:</strong> {pregunta_num}</p>"
            f"{formatted_list} ğŸ¤Œ"
        )
        return response_fragment

    except Exception as e:
        # log full traceback to your server logs
        traceback.print_exc()
        # return the error message in the HTTP response for debugging
        return f"âš ï¸ Error interno en el servidor:\n{e}", 500

# â”€â”€â”€ 5) Run server â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == '__main__':
    app.run(
        host='0.0.0.0',
        port=int(os.getenv('PORT','8000')),
        debug=False
    )
